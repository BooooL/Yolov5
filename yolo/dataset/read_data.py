#! /usr/bin/env python
# coding=utf-8
# @Author: Longxing Tan, tanlongxing888@163.com

import os
import cv2
import random
import numpy as np
from .augment_data import load_mosaic_image, random_perspective, random_flip, augment_hsv
from .image_utils import resize_image, xyxy2xywh, xywh2xyxy


class DataReader(object):
    '''
    read the image and label from the text information (generated by dataset/prepare_data.py)
    resize the image, and adjust the label rect if necessary
    augment the dataset (augment function is defined in dataset/augment_data.py)
    '''
    def __init__(self, annotations_dir, image_target_size=640, mosaic=False, augment=False, filter_idx=None):
        self.annotations_dir = annotations_dir
        self.annotations = self.load_annotations(annotations_dir)
        self.idx = range(len(self.annotations))
        self.image_target_size = image_target_size
        self.mosaic = mosaic
        self.augment = augment
        self.images_dir = []
        self.labels_ori = []  # original labels

        if filter_idx is not None:  # filter some samples
            self.idx = [i for i in self.idx if i in filter_idx]
            print('filter {} from {}'.format(len(self.idx), len(self.annotations)))

        for i in self.idx:
            image_dir, label = self.parse_annotations(self.annotations[i])
            self.images_dir.append(image_dir)
            self.labels_ori.append(label)

    def __len__(self):
        return len(self.annotations) 

    def __getitem__(self, idx):
        img, label = preprocess_image(idx, mosaic=self.mosaic, augment=self.augment, images_dir=self.images_dir, labels=self.labels_ori,
                                      image_target_size=self.image_target_size)
        img, label = resize_image(img, self.image_target_size, keep_ratio=True, label=label)  # resize the image and keep its wh ratio
        label[:, 0:4] = xyxy2xywh(label[:, 0:4])  # transfer xyxy to xywh
        return img, label

    def iter(self):
        for i in self.idx:
            yield self[i]

    def load_annotations(self, annotations_dir):
        with open(annotations_dir, 'r') as f:
            annotations = [line.strip() for line in f.readlines() if len(line.strip().split()[1:]) != 0]
        print('Load examples : {}'.format(len(annotations)))
        if 'train' in annotations_dir:
            np.random.shuffle(annotations)
        return annotations

    def parse_annotations(self, annotation):
        example = annotation.split()
        image_dir = example[0]

        label = np.array([list(map(float, box.split(',')[0: 5])) for box in example[1:]])
        # assert label.shape[1] == 5, "Label have and only have 5 dims: xmin, ymin, xmax, ymax, class"
        # assert np.max(label[:, 0:4]) <= 1, "Label box should be (0, 1), {}".format(annotation)
        return image_dir, label


def preprocess_image(index, mosaic, augment, images_dir, labels, image_target_size):
    if mosaic:  # mosaic need to load 4 images
        mosaic_border = [-image_target_size // 2, -image_target_size // 2]
        img, label = load_mosaic_image(index, mosaic_border, image_target_size, images_dir, labels)
    else:
        img_dir = images_dir[index]        
        img = cv2.imread(img_dir)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        label = labels[index].copy()

    if augment:
        if not mosaic:        
            img, label = random_perspective(img, label)
        img = augment_hsv(img)

    if augment:  # flip the data if it helps
        img, label = random_flip(img, label)

    img = img / 255.  # normalize the image
    if np.max(label[:, 0:4]) > 1:  # normalize the bbox
        label[:, [0, 2]] = label[:, [0, 2]] / img.shape[1]
        label[:, [1, 3]] = label[:, [1, 3]] / img.shape[0]
    return img, label

